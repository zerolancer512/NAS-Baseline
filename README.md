# Auto Generating a Deep Neural Network

# TODO
* Specifications for neural network DNA
* Generate TF estimator based on DNA
* Train TF estimator on CIFAR-10 and return validation accuracy
* Use tf.contrib.rnn.NASCell

# Basic algorithm
* Initialize controller
* Generate m child networks
* Write checkpoint
* Train m child networks and get m validation accuracies
* Calculate gradient from mean loss across child networks according to REINFORCE
    * This requires the EMA of previous architecture validation accuracies as a baseline function
* Update controller
* Repeat

# Parameters
* m - number of child networks to generate in one episode
* l - number of layers the child NN will have
* controller_lr - learning rate of controller
* child_lr - learning rate of child NN
* beta - weight decay parameter of child_NN for L2
* momentum - for Nesterov momentum of SGD

# Tokens generated by controller
* Filter size
* Stride size
* Nb. filters
* Max-pooling size
* anchor point